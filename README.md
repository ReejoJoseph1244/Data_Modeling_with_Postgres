# Data Modeling with Postgres

## **Overview**
In this project, I applied Data Modeling with Postgres and build an ETL pipeline using Python. A Business Consulation startup wants to analyze the data they've been collecting on Startups in different countries , their growth and Coperate taxes for their own Business Expansion and for consulting their Clients. Currently, they are collecting data in CSV format and the analytics team is particularly interested in understanding how the startup culture in the world for FY 2022..


## **countries_of_the_world Dataset**
countries_of_the_world dataset is generated by [kaggle](https://www.kaggle.com/datasets).

Sample Record :
```
{"Country":"India" , "Region": " ASIA (EX. NEAR EAST)", "Population": 1095351995 , "Area (sq. mi.)":  3287590, "Pop. Density (per sq. mi.)":  333,2, "Coastline (coast/area ratio)":  0,21, "Net migration":  -0,07, "Infant mortality (per 1000 births)":  56,29, "GDP ($ per capita)":  2900, "Literacy (%)": 59,5 ,"Phones (per 1000)" :  45,4,"Arable (%)" : 54,4  , "Crops (%)" : 2,74 , "Other (%)" : 42,86, "Climate": 2,5  , "Birthrate": 22,01,"Deathrate":  8,18 , "Agriculture" 0,186: ,"Industry" : 0,276  ,"Service" : 0,538}

```

## **country_tax Dataset**
country_tax dataset is generated by [kaggle](https://www.kaggle.com/datasets).

Sample Record :
```
{"Country":"France", "Tax Rate" : 25.80%}
```


## Schema

#### Fact Table 
**factdata** - contains the final data for Analysis

```
serial_key, country, position_key, Industry_key, Tax_key
```

#### Dimension Tables
**dimcountry**  - countries in the world 
```
country, region, population, area, net margration , gdp, industry
```
**dimposition**  - Countries position / ranking for startups in the world
```
country, total score, quantity, quality, business score
```
**dimindustry**  - industry specific country startup data 
```
industry, company, valuation, valuation date
```
**dimtax**  - coperate tax in each country
```
country, taxrate
```

## Project Files

```sql_queries.py``` -> contains sql queries for dropping and  creating fact and dimension tables. Also, contains insertion query template.

```create_tables.py``` -> contains code for setting up database. Running this file creates **startupanalysis** and also creates the fact and dimension tables.
 

```etl.py``` -> read and process **dimcountry** , **dimposition** , **dimindustry** and **dimtax**

## Environment 
Python 3.6 or above

PostgresSQL 9.5 or above

psycopg2 - PostgreSQL database adapter for Python


## How to run

Run the drive program ```main.py``` as below.
```
python main.py
``` 

The ```create_tables.py``` and ```etl.py``` file can also be run independently as below:
```
python create_tables.py 
python etl.py 
```


 #### Reference: 
[Psycopg](http://initd.org/psycopg/docs/)

[PostgreSQL Documentation](https://www.postgresql.org/docs/)

[Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)
